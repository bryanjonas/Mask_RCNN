{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"/home/dspuser/\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatDataset(utils.Dataset):\n",
    "    def scale_coord(self, geom, image):\n",
    "\n",
    "        scale_x = abs(geom[0] - image.bounds[0]) * abs(image.width / (image.bounds[0] - image.bounds[2]))\n",
    "        scale_y = abs(geom[1] - image.bounds[3]) * abs(image.height / (image.bounds[1] - image.bounds[3]))\n",
    "\n",
    "\n",
    "        return scale_x, scale_y\n",
    "    def preprocessing_image_ms(self, x, mean, std):\n",
    "        # loop over image bands\n",
    "        for idx, mean_value in enumerate(mean):\n",
    "            x[..., idx] -= mean_value\n",
    "            x[..., idx] /= std[idx]\n",
    "        return x\n",
    "\n",
    "    def load_sats(self, image_path, geojson_path):\n",
    "        from glob import glob\n",
    "        \n",
    "        self.add_class(\"sat\", 1, \"building\")\n",
    "        \n",
    "        image_glob = glob(image_path + '*.tif')\n",
    "        for idx, path in enumerate(image_glob):\n",
    "            self.add_image(\"sat\", image_id=idx, path=path,\n",
    "                          jsonPath=geojson_path)\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        from skimage.io import imread\n",
    "        # Load image\n",
    "        input_path = self.image_info[image_id]['path']\n",
    "        image = np.array(imread(input_path), dtype=float)\n",
    "        \n",
    "        bands = [4,2,1]\n",
    "        \n",
    "        \n",
    "        image = image[:,:,bands]\n",
    "        \n",
    "        #image = (image * 255) / image.max()\n",
    "        \n",
    "        mean_std_data = np.loadtxt('image_mean_std.txt', delimiter=',')\n",
    "        mean_std_data = mean_std_data[bands,:]\n",
    "        image = self.preprocessing_image_ms(image, mean_std_data[:,0], mean_std_data[:,1])\n",
    "        \n",
    "        return image   \n",
    "    \n",
    "    def load_orig_image(self, image_id):\n",
    "                \"\"\"Load the specified image (without stand.) and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        from skimage.io import imread\n",
    "        # Load image\n",
    "        input_path = self.image_info[image_id]['path']\n",
    "        image = np.array(imread(input_path), dtype=float)\n",
    "        \n",
    "        bands = [4,2,1]\n",
    "        \n",
    "        image = image[:,:,bands]\n",
    "        \n",
    "        image = (image * 255) / image.max()\n",
    "        \n",
    "        return image   \n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        import cv2\n",
    "        import os\n",
    "        import json\n",
    "        import rasterio as rio\n",
    "        import numpy as np\n",
    "        import scipy.ndimage as ndi\n",
    "        \n",
    "        geojson_path = self.image_info[image_id]['jsonPath']\n",
    "        input_path = self.image_info[image_id]['path']\n",
    "        \n",
    "        image_filename = os.path.split(input_path)[-1]\n",
    "        json_filename = 'buildings' + image_filename[14:-4] + '.geojson'\n",
    "        geojson_file = os.path.join(geojson_path, json_filename)\n",
    "    \n",
    "        #Load JSON\n",
    "        with open(geojson_file, 'r') as f:\n",
    "            geo_json = json.load(f)\n",
    "    \n",
    "        #Open image to get scale\n",
    "        image = rio.open(input_path)\n",
    "        image_shape = image.shape\n",
    "        #Load and scale all the polygons (buildings)\n",
    "        polys = []\n",
    "\n",
    "        for feature in geo_json['features']:\n",
    "            scaled_coordSet = []\n",
    "            if feature['geometry']['type'] == 'Polygon':\n",
    "                for coordinatesSet in feature['geometry']['coordinates']:\n",
    "                    for coordinates in coordinatesSet:\n",
    "                        scale_x, scale_y = self.scale_coord(coordinates, image)\n",
    "                        scaled_coordSet += [[scale_x, scale_y]]\n",
    "\n",
    "        \n",
    "            if feature['geometry']['type'] == 'MultiPolygon':\n",
    "                for polygon in feature['geometry']['coordinates']:\n",
    "                    for coordinatesSet in polygon:\n",
    "                        scaled_coord = []\n",
    "                        for coordinates in coordinatesSet:\n",
    "                            scale_x, scale_y = self.scale_coord(coordinates, image)\n",
    "                            scaled_coord += [[scale_x, scale_y]]\n",
    "                    scaled_coord = np.array(scaled_coord)\n",
    "                scaled_coordSet += [scaled_coord]\n",
    "\n",
    "            geom_fixed = np.array(scaled_coordSet, dtype=np.int32)\n",
    "    \n",
    "            if geom_fixed.shape[0] != 0:\n",
    "                polys += [geom_fixed]\n",
    "        \n",
    "        polys = np.array(polys)\n",
    "\n",
    "        mask = np.zeros(image_shape)\n",
    "        cv2.fillPoly(mask, polys, 1)\n",
    "    \n",
    "        mask = mask.reshape(mask.shape[0], mask.shape[1])\n",
    "        \n",
    "        segs, count = ndi.label(mask)\n",
    "        if count == 0:\n",
    "            maskArr = np.empty([0, 0, 0])\n",
    "            class_ids = np.empty([0], np.int32)\n",
    "        else:\n",
    "            maskArr = np.empty((segs.shape[0], segs.shape[1]))\n",
    "            class_id_list = []\n",
    "            for i in range(1, count+1):\n",
    "                intArr = (segs == i)\n",
    "                intArr.astype(int)\n",
    "                maskArr = np.dstack((maskArr, intArr))\n",
    "                class_id_list += [1]\n",
    "            maskArr = np.delete(maskArr, 0, axis=2)\n",
    "            \n",
    "            class_ids = np.array(class_id_list)\n",
    "        return maskArr, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_inf = SatDataset()\n",
    "dataset_inf.load_sats(image_path, geojson_path, type='inf')\n",
    "dataset_inf.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(SatsConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "stan_image, orig_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id)\n",
    "\n",
    "log(\"orig_image\", orig_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(orig_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([stan_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
